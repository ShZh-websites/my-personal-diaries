---
keyword: "回忆"
title: "我的大学：大二"
date: "2020-06-29"
desc: "当初有很多人在写回忆，我也跟风写了一点，但是那个时候课业繁重，大二的生活我就只写了一个大纲，今天我把他扩写成一片完整的文章。"
---

# 人工智能

大一大二衔接的那个暑假，辅导员推荐了一个免费的校外培训班。这个培训班是帮你入门人工智能的。我那时虽然对人工智能一无所知，但是非常希望接触人工智能，所以便报名了。彼时我还住在工学部，离培训班非常远，每天最痛苦的事情就是去上班。首先找一辆共享单车骑到信息学部（当时还没有共享电动车），然后坐一班地铁，最后再走一段相当长的距离。由于在路上要花费相当长的时间，所以我不得不很早起床。有时运气不太好，没找到共享单车，那就等着迟到挨批评吧。

上这个培训班我最大的收获便是结交了一群同校人工智能的大佬，比如zth学长，ywt同学，还有和我一起吃饭的yx同学等。他们在刚上大学的时候都有不同程度地接触人工智能，有不少已经在相关赛事上取得了非常不错的成绩。培训班每天中午都会有技术分享，轮到我时我只能上去介绍最简单的算法复杂度，而其他人却能把自己做的项目搬出来介绍。这个时候我深深感受到了同龄人之间的差距，于是我便下定决心大二这一年认真学习人工智能。

我制定了详细的学习计划：一开始先看完吴恩达机器学习和深度学习的课程，期间用西瓜书、花书和《统计学习方法》做补充，接着看《动手深度学习》复现传统机器学习算法，然后去kaggle上打一些入门的小比赛，这些都做完后差不多就可以去参加国内的大比赛了，如果还想继续深入就参加校内老师的实验室。 除了加入实验室外，这些任务我都悉数完成了。在大二的末尾，连我自己都觉得自己的基础非常扎实了。

不参加实验室和我对上大学的理念有关，这一点其实深受YY硕的影响。我认为本科阶段应该尽可能广泛地学习，扩展自己的视野；等你读研或者工作后有的是时间研究某一具体的领域，所以自打入学以来我就没想过加入实验室。另外学到后期我对人工智能也没有太大热情了，再加上当时人工智能的热度有所消退，我便逐渐萌生了转行的想法。思想上的转变也是我没有参与科研的另一个重要原因。

本篇主要围绕我在学习人工智能的过程中参加的几个比赛来展开。因为比赛在保研中也占了相当大的比重，而且当时我对保研还抱有一定希望，所以你可以看到我在这一年中疯狂参加各种比赛。



# 数维杯

数维杯是flb带着我参加的，这是我参加的第一个数学建模竞赛，也是我大学期间正式参加的第一个比赛。

我们组每个人的个人能力都很强：flb在我心中拥有着计算机系最强的数学水平；我们组还有一位是电气GPA排第一的学长ljq，他的英语水平也是怪物级别。相比之下我就比较逊色了，更何况我那时对数据科学的认识还在停留入门阶段，最后仅在zth学长的指导下用SPSS，Matlab和Excel做了一个最简单的GLM，还没有进行预处理、观察分布和剔除无用特征等操作。有一题明显要用时间序列，我也没看出来（虽然看出来了也不会做），更绝的是当初我画图竟然是用Excel内置的样式画的，用什么画图其实无所谓，关键是我画蛇添足地用了Excel里花哨的模板。就这样队友们的努力都被我付之一炬，最后只拿了个三等奖。不过考虑到这是我第一次参加比赛，三等奖我还算满意。



# APMCM

这个是经管研二的hxx学长带着我参加的又一个数学建模竞赛。当初是他和我另两个舍友参加数维杯的比赛。在他打完数维杯之后还想参加这个APMCM，但是我的舍友已经不想参加了（不想熬夜），所以他们就把学长推荐给了我。这个比赛同样需要三人参加，我最后在浙江老乡群里找到了hth。至此我们组集齐了数模的三个黄金专业：计算机、经管和数院，而且经管和数院也是我们学校的强势专业，所以说我们的阵容堪称完美。

在学长的督促之下，我们为这个比赛做了非常充分的准备。在比赛前，hxx学长就召集我们研读前几年的优秀论文。为了提高效率，我们也不在寝室远程讨论了，而是去经管学院找了一间空教室使用，就连吃饭也在经管院点外卖吃了。当时我已经有数据处理的经验了，又有两个大腿可以抱，所以最终成绩比较理想，拿了个二等奖，差一点就摸到一等。



# 美赛

在尝到数学建模的甜头后，我和hth决定进一步参加美国大学生数学建模竞赛。这个比赛很有名，学校里有很多人参加。我们和其他人相比已经有建模比赛的经验了，所以我们定了很高的目标。由于美赛是不允许研究生参加比赛的，所以我拉了GPA同样很高，关系和我也不错的mgh同学一起参加。

刚开始我们在题目的选择上产生了分歧，hth想选个以建模为主的题目，因为他之前系统学过相关的理论，这种题目是驾轻就熟的，但是同为计算机专业的我和mgh就只能干瞪眼了。我俩更想选一个NLP的题目，毕竟我和他都有NLP的经验，但这下就轮到hth同学瞪眼了。最终两个人的意愿战胜了一个人的意愿。这里要点名表扬一下hth同学，即便是面对不想选的题目，他依旧做的非常认真，一个人把第二题的五个小问全写了，出的力一点不比两个计算机的少。但是我们错误估计了论文的篇幅，正文上限18页我们写了22页，就连最基础的洗数据都写了两页。所以在ddl之前我一直在压缩内容，但是添加容易、删除困难，论文里的很多内容都不能被轻易删减，删了逻辑就不连贯了。最后我改了一篇连我自己都不忍直视的文章，不出意外地捞了个最差的SP奖。

看到有些同学第一次参加数模就能拿到比我们好的成绩，我心里很不是滋味。此役过后，我下决心不参加任何数学建模比赛，已经算是半个数学建模老手的我深知这种比赛有多么浪费时间：

- 在三四天的时间内让学生写一篇学术论文，这实在是太扯淡了，更何况学生可能对论文的方向一无所知；
- 参赛者为了完成这种畸形的需求，还常常得熬夜，消耗自己的身体；
- 最后因为大家论文专业性都不够，这种比赛就沦为了选美大赛，比谁图画的好；

参赛者唯一能得到的，就是获奖时的虚荣。所以说如果你是抱着功利的心态参加比赛，那么数学建模真是再适合不过了。



# 服创

告别了无聊的数学建模，我迎来了真正意义上的人工智能比赛。那个时候我刚把传统机器学习学完，就想着能不能参加一个结构化数据集的项目，刚好服务外包创新创业大赛上有这样一个题目符合我的要求。顺便提一嘴，在之前的一次实验课上我认识了lyx同学，他广阔的视野和渊博的学识给我留下了深刻的印象，从此我俩就像连体婴儿一样抱团做各种项目，这次的服创和下文提到的大创和软件杯都是和他一起参加的。

我选择的题目是僵尸企业识别，就是给你某个企业的各种特征，判断这个企业是否是僵尸企业。一开始我先使用随机森林撸baseline，准确率已经能达到98%了。这个时候其他参赛队伍也对这个题目产生了疑问，不管用什么方法，准确率都高得离谱，即便是用最简单的线性回归，准确率也高达90%，那这个题目还有什么意义呢？网安的机器学习老师在得知这件事后，也跟我们说：现在低质量的机器学习比赛太多，不要在这些事情上投入太多时间。然而当时的我并没有听信这句话。于是我继续尝试用model ensemble看看有没有什么提升，结果准确率不升反降。同时期lyx的神经网络准确率已经能够超过99%了，组内一致决定用他的模型。我寻思着那我不是什么都没干嘛，于是继续eda，发现了只要把三个特征加起来，判断一下它是否大于零（用专业的术语说，这叫两层的multivariate decision tree），就能在原始训练集上达到100%的准确率，验证集上的准确率也有99.94%。

组内对是否采用我这个方案产生了严重的分歧。lyx认为我的方案把主办方底裤都给扒了，这种方案是不可能拿奖的，因为它让其他所有参赛选手的努力都成了笑话。反正这个比赛也不重要，不如就把他写的神经网络交上去混混得了；在我看来他写的网络太简单，交上去同样获不了奖，已知我的方案不论是从准确率还是性能都是无出其右的，不如我们就从这个结果出发，论证这个方案的正确性。最终我们决定把所有模型都写上，然后对比得出100%准确率的那个方案是最好的。

这个比赛最后会把测试集发给各个选手，然后我们需要把在测试集上预测的结果发给主办方。结果公布测试集的那天，发生了一件令人震惊的事：测试集里竟然带了真实值！我做梦都没想到他们会这么业余。我把我的模型在这个测试集上跑了一下，准确率依旧是100%！同样其他方案的准确率也高达90%+。一开始我还怀疑这个测试集是不是从训练集里面挖的，结果跑了一下发现数据并没有重合。这下我基本上确认了，我们组的解决方案就是最好的，服创一等奖预定。主办方发现自己犯蠢了之后，又重新发了一个测试集，这个测试集倒是不带真实值了。我们同样在这个新测试集上跑了多个模型，没想到预测的重合度开始不到50%了。如果跟之前一样，各个方案的准确率都在90%以上，那么预测的重合度应该是相当高的。我很确信数据的分布被人为地改变了，我们的方案被强制失效了！

这个时候队伍里又出现了争论，因为数据分布改变后，那个100%准确率的方案不再可靠，然而我依然坚持不改动方案。当然最后证明我还是太天真，这个比赛我们连三等奖都没捞着，这门多天的努力全白费了。之前我说其他组的努力是徒劳，没想到小丑竟是我自己！这个比赛我学会一个教训，那就是比准确率一定要有一个像Kaggle那样公开的、实时的leaderboard，不然主办方很可能看你不顺眼下黑手。那么这个比赛想要获奖该怎么做呢？我觉得lzt组给出了答案，他们是用LGB做了单模，准确率只有堪堪90%，但是最后却收获了国家二等奖，所以这个比赛实际上并不是像主办方所说的那样，是个比准确率、比性能的项目，而是看谁用的模型新颖，谁比较会吹。

这件事情对我影响很深远，我开始逐渐质疑大学期间所有比赛的含金量。其实我之所以对比赛有这么深的执念，有相当一部分原因是因为我高中的时候没进春季班，和五大竞赛擦肩而过，而大学期间我想弥补这个遗憾，但是比赛的含金量已经不能同日而语了。最终我得出结论：大学期间99%的比赛都是狗屎。作为一个本科生，你的首要任务是学习和沉淀，而不是用自己三脚猫的水平去产出，去证明自己的狗屁实力。真有这个时间不如好好看看黑皮书，看看人家的文档，不要白白浪费自己的时间和生命！

【P.S.】上文我说大部分比赛都是💩，那么有没有不是💩的比赛呢？其实是有的，比如ACM，比如龙芯杯，比如SC、ASC、ISC这种超算比赛等。鉴别一个比赛是否有含金量有一个极其简单的标准，那就是看有没有清北交浙的同学参加，如果这些学校的队伍不在少数，那基本上是很有含金量的了。



# 大创

大创和之前提到的比赛都不一样。不论是数学建模还是服创，都是主办方给你题目，但是大创是你自己想题目，因此你最好有个idea。像这种选题不固定的比赛竞争往往都很激烈，有很多已经出名并且融资成功的项目会来参加，比如摩拜单车当年还参加了互联网+；还有很多人本科四年就做了一个项目，你得和这样的项目竞争。lyx告诉我他的舍友就属于后一种情况，他们的题目是用CV技术探测药品包装的缺陷，他的舍友从入学的时候就在着手准备这个项目了，甚至他选的课程、学的知识都是围绕这个题目的。而我就不一样了，我搞大创仅仅是为了能在保研和申请奖学金的时候获利，这使得我在一开始的时候就落后于别人。

因为我们并没有提前想好的idea，所以还得从零想一个题目。于是我召集了组员在漫咖啡里做brainstorm，有人说要用机械臂做垃圾的自动分类（彼时上海推出了严格的垃圾分类政策），但是lyx认为这低估了机械臂的难度；还有人说可以参考去年国家级大创的题目，做一个去雾的应用。每个人都有自己的想法，最终也没有讨论出个所以然来。

搞大创还需要找一个指导老师，我们组里的学姐推荐了韩镇老师。lyx和我决定找指导老师的同时，看看他能不能给我们几个选题参考参考。要知道有很多人的大创题目并不是他们自己想的，而是他们所在的课题组扔给他们的，有很多甚至已经做出成果了。于是某天上午我们就去本科生院找韩镇老师讨论了。整个过程中我基本没说什么话，全是lyx和韩老师在交流。韩老师表示他是做人工智能安全领域的，所以只能给我们几个安全有关的课题参考，但我实在对安全不感冒。回到寝室后我又仔细想了想，觉得对比之下还是去雾好做一些，于是告诉大家我们的题目定了，就是去雾。

写完计划书后大创就搁置了。几个月后大创公开选题，我发现其中并没有我们的，这说明大创申报失败了。这下我有点慌了，因为作为队长，负责申报的人是我。于是我赶紧去问负责人是哪里出了问题，有没有什么补救的措施。他询问我指导老师是不是没有确认，我看了一眼果然。原来大创不仅要提交计划书，还要指导老师的确认。我在提交申报书之后，既没有主动提醒韩镇老师，他也没有主动确认，所以我们的大创就无了。

大创这件事就这样胎死腹中了。作为本科期间唯一流产的项目，我对各个组员还是很愧疚的，毕竟这100%是我的锅。好在这件事情并没有太大的影响，该保研的还是保研了，没有耽误大家。而且现在看来我不觉得能做出来，因为我们的题目其实就是单纯的去雾，只能改进改进现有的模型，但是你一个近乎零基础的本科生，在没有老师和实验室的帮助下，怎么可能随随便便超过人家的SOTA呢？真当深度学习是儿戏？



# 软件杯

软件杯是我本科期间参加的最后一个比赛，可能有人会问：你搞完服创后不是不参加任何比赛了吗？怎么又搞了软件杯呢？实际上软件杯的报名远在服创之前。如果说之前搞服创是为了参加传统机器学习的比赛，那么我参加软件杯则是为了参加深度学习的比赛。

我还特地选了一个和图像处理相关的题目，大致是在路口用图像处理完成各种交通任务，比如判断闯红灯啊、抓出违规车辆什么的。这个题目的任务其实非常艰巨，除了必做的行人车辆跟踪和红绿灯检测外，还有车道线识别和车速计算等加分项。这个比赛仅限制三个人参加，每个人的任务都非常重，像我就包了整个图像处理模块了，而lyx就负责一个人写前后端。

说实话我不是很想回忆这段经历，实在是太痛苦了。首先数据集就很难找，因为题目要求追踪的东西非常多，你手动标注训练显然不现实，开放的数据集又很难找到合适的，比如车辆和车牌的数据集就很难找，毕竟这些都是隐私信息。能找到的基本都是国外的，但是在国外数据集上训练出来的模型必定水土不服。而且那个时候我也缺少算力，所有的训练和推理都是在笔记本上进行的，我笔记本的显卡又是Nvidia的1050ti，你可以想象我有多煎熬了。有些功能实在找不到对应的数据集，就只能用传统的图像处理硬上了。而传统的图像处理方法有一个非常大的缺陷，那就是泛化性差，你对着一张图调出来的参数在别的图片上效果不一定好，这点远不如神经网络，我调了很久才找到一个差强人意的，这一过程相当折磨，因为调参是靠大量时间堆出来的，是一个纯纯的体力活。

最后终于磕磕绊绊地把这个项目做完了：

- 目标识别方面，因为要识别的很多，所以我干脆找了一个在COCO数据集上预训练好的yolo v4模型（结果没几天后就有了yolo v5），然后用DeepSort改成了多目标追踪；
- 人行道的识别，我找了几个语义分割网络，然后找来一个人行道数据集进行训练，选了一个肉眼看上去效果最好的；
- 车牌的识别，因为找不到合适的数据集，我就当了一回调包侠，用了现成的中文车牌识别库；
- 车道和车道线的识别，我综合使用了好几个传统算法才做出来。

车速计算的功能我也尝试过。在查阅了一些资料之后，我发现想要在缺少高度信息和摄像头内参的情况下算出车速有点不太现实，一些前沿的论文中提到的用3 VP推导intrinsic matrix和用Monocular Depth Estimation推导extrinsic matrix的方法或许可行，但是我已经没精力去尝试了。

这个比赛我们最后是拿了国三，说实话不太理想，因为我们同班同学拿了国二（当然一个很重要的原因是他们有3080ti的加持）。这次失利场外原因有很多，比如我们的指导老师建议不要花太多时间在比赛上，所以我们在过了初赛以后就开始摆烂了，没有继续调整和优化这个项目；另外服创的事情对我打击也很大，我已经不愿意在比赛上花更多时间了。不过最主要的肯定还是自身实力的问题，当时对软件的理解太浅薄了，导致这个项目有非常多的缺陷：

- 各个没有依赖的任务竟然是串行处理的，这严重拖累了FPS。完全可以改造成并行处理，这样即使一台计算机算力不够也可以很轻松地用分布式做扩展；

- 当时不会流媒体，所以视频的标注是靠ffmpeg分割成帧，然后在每一帧上画图，最后再用ffmpeg合并成一个完整的视频。这个真是太愚蠢了，一定有更好的解决方案；
- 那时既也不知道HLS也不懂Range，所以后端给前端发送视频的时候，视频甚至不是边下载边播放的，前端必须下载好一个完整的视频才能开始播放；
- 我们后端是用Node写的，而图像处理模块是用Python写的，这就要求这两种语言进行交互。当时的方法是在Node里开一个shell进程，然后通过执行命令创建Python子进程，这就是脍炙人口的命令行方法。后来才了解到这个场景不就是IPC嘛，其实有很多更杨戬的办法来解决这个需求，RPC也是一个不错的选择。

让现在的我来看，这个项目写的真是烂到家了。但是它在功能上还算比较完整，所以在还Github上时不时会有人点个star（虽然在我看来来是在处刑我）。目前为止这个项目的star数依然是我所有仓库中最多，很多时候我羞愧地想删库跑路，但是它star实在是太多了，有点于心不忍。至此我的竞赛生涯终于结束了，虽然软件杯并没有起到预想中以赛代练的效果，但是它让我看清了自己的不足，为今后的努力指明了方向。它的质量起码比服创要高。



# 横向

大二的寒假我被舍友骗去做了一个横向。当时他蛊惑我说做这个能发论文，我没忍住诱惑就去了（其实天底下哪有这么好的事情，学弟学妹们遇到类似的事情别被骗了）。做的是一个和铁四院合作的岩土识别项目，不论是学术界和工业界都有人搞这个，但是都没成功，所以这个老师拉了几个本科生来做了（？）

内容就是识别岩芯箱中泥土的种类，看上去简单，实际上坑非常多。首先图片的背景非常复杂，这些照片都是工人实地拍摄的，岩芯箱可能放在水泥地上，也可能放在草堆里，背景没有你想象的那么干净；另外拍摄的时间也有很大差异，有的是在正午拍的，光线充足，还有的是在晚上拍的，光线昏暗，还有的我看是拍照者故意整你心态，在岩芯箱上给你整点影子，这下更难识别了。就算你能提取出岩芯箱，岩土也很难被正确地分类，有些岩层的泥土颗粒比较粗，但是工人在钻孔的时候，这些泥土可能会在外力的作用下被碾成细小的颗粒；有些岩土的颜色很特别，但是加上光照和阴影后又不一样了。总之这个题目确实很有难度，当初为了从图片中提取出岩芯箱，老师不断给甲方提要求，一开始是要给箱子周围加上标记方便前景识别，到后来干脆定制岩芯箱了。我负责部分的是岩土切割，就是用霍夫变化和一些数学运算把岩芯箱中的岩土提取出来。写完这部分我就赶紧跑路了，我实在不觉得这个项目能完成。

这次横向算是我本科期间唯一的科研经历了。第一次开组会的时候，其他人都说自己为项目做了些什么，而我还在学相关知识，就跟大家介绍了一下我的学习进度，结果全场都被我搞沉默了。当初我们组会是一星期开一次，一般我是前五天摸鱼，到最后两天要报告进度了，赶紧学点/做点什么，这让幼小的我深切地体会到了开组会的恐惧。



# 强化学习

大二的寒假我还把强化学习学了。契机是我当初在Github上follow了一个很优秀的zh学长，他在同时期到处star强化学习的项目。我寻思着我可以把他star的项目全看了，这样相当于早他一年学强化学习，我不就比他更强了吗？

于是我精选了一个讲解强化学习的博客，用PyTorch和OpenAI的gym实现博客上介绍的各种算法，如果有bug就对照着看其他人基于Tensorflow的实现（那个时候基于PyTorch的实现还少的可怜，不像现在这样烂大街）。实现完大部分算法后我还去看了李宏毅的相关课程和一点强化学习圣经，可惜寒假很快就结束了，我也没有时间继续深入了。



# 疫情

2020年年初武汉爆发了新冠疫情，早在19年底群里已经有各种流言了，我下楼的时候也看到有同学带着口罩，但没想到后来事情会那么严重。万幸的是学校赶在疫情爆发和武汉封城之前放假了。后来疫情蔓延到全国，我的大二下半学期也全都在家里度过。

疫情给教学带来了两个改变：第一是线下教学改成上网课了，这给了我很多操作的空间：

- 早八的课我基本上是八点醒来签个到，然后便继续睡了；
- 有些课（比如计算机网络）在上课结束后发录屏，于是我干脆不上网课，而是2.5倍速看录屏，效率更高；
- 还有些课我不怎么感兴趣（比如iOS程序设计，实际上我对客户端都不怎么感兴趣），干脆全翘了。

第二是一些考试不方便闭卷了，于是很多便改成了论文的形式。有个别课程依然坚持闭卷，为此他们加了很多限制，比如组合数学、操作系统和数据库就引入了双机位来监控。英语考试学校自作聪明地搞了个桌面应用来防作弊，一旦打开这个软件你就无法跳转至桌面或者其他应用，这样你就不能用谷歌翻译这种翻译软件查单词了。但是基于客户端的措施一定是防君子而不防小人的，可惜学校并没有认识到这点，聪明的你一定想到了用Windows自带的多开桌面可破。有了这个应用之后学校非常自信地没有在英语考试时开启监视，我寻思着就算别人想不到多桌面，他们也可以在考试时连麦啊，这也太瞧不起学生的创造力了。疫情期间体育课的形式也发生了很大的改变，课后作业变成了拍自己锻炼的视频。尽管如此那段时间我依旧是疏于锻炼，体重暴涨到了80kg，后续征兵的时候也因为体重原因没过。

疫情期间老师给分比较宽松，大家的成绩都很高，有一些同学也在空间里炫耀自己近乎全满绩的成绩单。相比之下我的成绩单就比较惨了，清一色的八十几，甚至有几门连八十也没上。说实话想让每门课都有一个高绩点其实并没有那么容易，据我所知你得做到以下几点：

- 首先在选课的时候就得到处打听，选的老师讲课不一定好，但是给分一定要高。当初我们教务系统改革，必修课是按照行政班分配的，有些追求高绩点的人眼看分到了一个不好的老师便马上退课。而我因为懒惰就没做这种事；
- 其次要及时、高质量地完成课后作业。我课后作业都是随便做做的，后期甚至结课论文都是随便写的；
- 最后要预留足够的时间复习考试。我本科期间考试都是前两天才开始复习，到后期甚至前一天才开始复习，等到上考场了，我连PPT都没看完，然而我的舍友可能已经把历年试卷都做了一遍了。

还有些很有帮助的技巧，比如上课坐前排、与老师积极互动等等，至于什么2k字的论文强行扩写到1w字，和老师私聊显存在感等等，这些高级技巧我反正是学不会。

第三学期也是在家里上的，一门叫《前沿理论》的课发生了一件让我印象深刻的事情。这门课我们学院请了澳大利亚的华裔老师来给我们授课。一开始这门课是全英文授课的，所谓全英文就是讲课用英文，课件用英文，论文也得用英文写。后来他怕我们有些同学跟不上，就改成了用中文讲课。其实这种形式的课程在每个学校里都有，没什么稀奇的。但是有些同学就不乐意了，尤其是用英文写论文这一点，他们极为反对。于是老师做出了让步：你可以用中文写，但是这样分数就上不了90。这下他们更不乐意了，大喊着要退课。我至今都搞不清楚他们的脑回路，既然不按照老师要求的来，那你就不配拿高分啊。另外上课为什么一定要追求满绩呢？你觉得自己学到东西了不就行了，是不是我们学院课程动不动的满绩把你给宠坏了？互联网上铺天盖地对「卷」的声讨，不应该成为自己懒惰的借口。



# 总结

虽然这篇文章显示的时间是2020年，但是它实际是我在大四的时候写的。在写这篇博文的时候，我无时无刻不为自己当初孱弱的实力感到震惊，为什么那时的我有这么菜啊，同时也深深庆幸自己做出了正确的决定，后两年我没有参加任何比赛，而是潜心钻研自己感兴趣的东西，最终计算机技术突飞猛进，和当初的我相比简直是判若两人。大三开始有很多人为了保研也开始胡乱地参加比赛了，看着这帮人就感觉看着过去的自己。